---
title: "Biostat 212A Homework 3"
subtitle: "Due Feb 20, 2024 @ 11:59PM"
author: "Jiyin (Jenny) Zhang, 606331859"
date: today
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
engine: knitr
knitr:
  opts_chunk: 
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
    cache: false
---

## ISL Exercise 5.4.2 (10pts)
Suppose that we use some statistical learning method to make a prediction for 
the response Y for a particular value of the predictor X. Carefully describe 
how we might estimate the standard deviation of our prediction.

### Answer:
We can estimate the standard deviation of our prediction by using the bootstrap 
method. We can obtain repeated random samples from the original data set without 
generating additional samples. To elucidate, we perform sampling with replacement 
B times and then find the corresponding estimates and the standard deviation of 
those B estimates by using the following equation:
$$
SE_B(\hat\alpha) = \sqrt{\frac{1}{B-1} \sum_{r=1}^B (\hat\alpha^{*r} - \frac{1}{B} \sum_{r=1}^B \hat\alpha^{*r'})^2}

$$
where $\hat\alpha^{*r}$ is the estimate of $\hat\alpha$ for the $r^{th}$ 
bootstrap sample and $\frac{1}{B} \sum_{r=1}^B \hat\alpha^{*r'}$ is the average 
of the B estimates.

## ISL Exercise 5.4.9 (20pts)
We will now consider the Boston housing data set, from the ISLR2 library.
__(a)__ Based on this data set, provide an estimate for the population
mean of `medv`. Call this estimate $\hat\mu$.
### Answer:
```{r}
library(ISLR2)
data("Boston")
head(Boston)
mu_hat <- mean(Boston$medv)
cat("The population mean of medv is:", mu_hat, "\n")
```

__(b)__ Provide an estimate of the standard error of $\hat\mu$. Interpret this
result.
Hint: We can compute the standard error of the sample mean by dividing the 
sample standard deviation by the square root of the
number of observations.
### Answer:
```{r}
se_mu_hat <- sd(Boston$medv) / sqrt(length(Boston$medv))
cat("The estimate of the standard error of the population mean of medv is:", se_mu_hat, "\n")
```

__(c)__ Now estimate the standard error of $\hat\mu$ using the bootstrap. How
does this compare to your answer from (b)?
### Answer:
```{r}
# Install the boot package if you haven't already
# install.packages("boot")
# Load the boot package
library(boot)
```

```{r}
set.seed(1)
boot.fn <- function(data, index) {
    mu <- mean(data[index])
    return (mu)
}
boot_stat = boot(Boston$medv, boot.fn, 1000)

# Extract the standard error from the bootstrap result
standard_error <- sd(boot_stat$t)

# Print the standard error using cat
cat("Standard Error:", standard_error, "\n")

```
The bootstrap estimated standard error of $\hat\mu$ is very close to the 
estimate found in (b).

__(d)__ Based on your bootstrap estimate from (c), provide a 95 % confidence
interval for the mean of medv. Compare it to the results
obtained using t.test(Boston$medv).
Hint: You can approximate a 95 % confidence interval using the
formula [ˆμ − 2SE(ˆμ), ˆμ + 2SE(ˆμ)].
### Answer:


__(e)__ Based on this data set, provide an estimate, ˆμmed, for the median
value of medv in the population.
### Answer:


__(f)__ We now would like to estimate the standard error of ˆμmed. Unfortunately,
there is no simple formula for computing the standard
error of the median. Instead, estimate the standard error of the
median using the bootstrap. Comment on your findings.
### Answer:


__(g)__ Based on this data set, provide an estimate for the tenth percentile
of medv in Boston census tracts. Call this quantity ˆμ0.1.
(You can use the quantile() function.)
### Answer:


__(h)__ Use the bootstrap to estimate the standard error of ˆμ0.1. Comment
on your findings.
### Answer:




## Least squares is MLE (10pts)

Show that in the case of linear model with Gaussian errors, maximum likelihood and least squares are the same thing, and $C_p$ and AIC are equivalent.

## ISL Exercise 6.6.1 (10pts)

## ISL Exercise 6.6.3 (10pts)

## ISL Exercise 6.6.4 (10pts)

## ISL Exercise 6.6.5 (10pts)

## ISL Exercise 6.6.11 (30pts)

You must follow the [typical machine learning paradigm](https://ucla-econ-425t.github.io/2023winter/slides/06-modelselection/workflow_lasso.html) to compare _at least_ 3 methods: least squares, lasso, and ridge. Report final results as

| Method | CV RMSE | Test RMSE |
|:------:|:------:|:------:|:------:|
| LS | | | |
| Ridge | | | |
| Lasso | | | |
| ... | | | |

## Bonus question (20pts)

Consider a linear regression, fit by least squares to a set of training data $(x_1, y_1), \ldots, (x_N,  y_N)$ drawn at random from a population. Let $\hat \beta$ be the least squares estimate. Suppose we have some test data $(\tilde{x}_1, \tilde{y}_1), \ldots, (\tilde{x}_M, \tilde{y}_M)$ drawn at random from the same population as the training data. If $R_{\text{train}}(\beta) = \frac{1}{N} \sum_{i=1}^N (y_i - \beta^T x_i)^2$ and $R_{\text{test}}(\beta) = \frac{1}{M} \sum_{i=1}^M (\tilde{y}_i - \beta^T \tilde{x}_i)^2$. Show that
$$
\operatorname{E}[R_{\text{train}}(\hat{\beta})] < \operatorname{E}[R_{\text{test}}(\hat{\beta})].
$$